`preprocessing.py` needs about 13GB of RAM. Decrease the batch size if you have less.
Alternatively consider trying the `GPT2TokenizerFast` instead of `GPT2Tokenizer`.